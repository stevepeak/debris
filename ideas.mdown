

|  **Key**  |  **Type** | **Default** |    **Description**     |
| :-------- | :-------- | :---------- | :--------------------- |
| **ttl**   | `integar` | `infinity`  | seconds till expires   |
| **evict** | `boolean` | `false`     | if data can be evicted |
|           |           |             |                        |


Sources = amazon, redis, mongodb, postgresql, memcache

```json
{
    "orders": {
        // tries each source in sequential order
        // "memory": false, use a dict to define more arguments
        "memory": {
            "ttl": null
        },
        "get": ["mongodb", "postgresql"],
        "put": [
            {
                "service": "mongodb"
            },
            {
                "service": "postgresql",
                "query": "SELECT order_assemble(%s::int) as data limit 1;"
            },
            {
                "service": "redis"
            },
            {
                "service": "amazon",
                "bucket": null,
                "folder": null
            }
        ]
    }
}
```

- remove __assemble__, assemble from the Cashe Routes
- when data is needing to be updated, need to update all the services
- worker dynos to garbage collect and manage data??
